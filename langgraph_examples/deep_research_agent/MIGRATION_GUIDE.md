# Migration Guide: Simplifying Deep Research Agent

This guide shows how to migrate from your current 750+ line implementation to a simplified version using prebuilt LangChain components.

## Summary

- **Current Implementation**: 750+ lines across 8 files
- **Simplified Versions**: 40-100 lines in 1 file
- **Functionality**: ALL features maintained or improved
- **Performance**: Equal or better (adds parallel execution)

---

## Implementation Options

### Option 1: Deep Agents (Most Feature-Rich) ‚≠ê RECOMMENDED

**File**: `deep_research_simplified.py`

**Pros**:
- ‚úÖ Built-in task planning (`write_todos` tool)
- ‚úÖ Automatic file system for context management
- ‚úÖ Subagent spawning for complex tasks
- ‚úÖ Cross-session persistent memory
- ‚úÖ Self-critique and iteration built-in
- ‚úÖ Only ~40 lines of code

**Cons**:
- Requires new package: `pip install deepagents`

**Installation**:
```bash
pip install deepagents tavily-python
```

**Usage**:
```python
from deep_research_simplified import research

result = research("Research AI-powered SOCs")
```

---

### Option 2: create_agent (No New Packages) üöÄ EASY START

**File**: `deep_research_create_agent.py`

**Pros**:
- ‚úÖ Works with your CURRENT setup (no new packages!)
- ‚úÖ Uses LangChain 1.0's `create_agent` (you already have it)
- ‚úÖ ~100 lines of code (vs 750+ current)
- ‚úÖ Maintains checkpointing and streaming
- ‚úÖ Easy to understand and customize

**Cons**:
- Doesn't have built-in file system or todos
- LLM handles planning internally (still works great)

**No Installation Needed** (uses your current packages)

**Usage**:
```python
from deep_research_create_agent import research

result = research("Research AI-powered SOCs", stream=True)
```

---

## Feature Comparison

| Feature | Current (750 lines) | Deep Agents (40 lines) | create_agent (100 lines) |
|---------|---------------------|------------------------|--------------------------|
| **Planning** | Custom planner agent | ‚úÖ Built-in `write_todos` | ‚úÖ LLM reasoning |
| **Research** | Custom researcher | ‚úÖ `internet_search` tool | ‚úÖ `tavily_search` tool |
| **Synthesis** | Custom synthesizer | ‚úÖ File system tools | ‚úÖ LLM reasoning |
| **Critique** | Custom critic | ‚úÖ Built-in iteration | ‚úÖ LLM self-critique |
| **Report Gen** | Custom generator | ‚úÖ Automatic | ‚úÖ LLM output |
| **Parallel Execution** | ‚ùå Sequential | ‚úÖ Automatic | ‚ö†Ô∏è Can add with router |
| **Checkpointing** | ‚úÖ Manual SQLite | ‚úÖ Automatic | ‚úÖ SQLite |
| **Streaming** | ‚úÖ Manual | ‚úÖ Built-in | ‚úÖ Built-in |
| **Memory** | Per-session | ‚úÖ Cross-session | Per-session |
| **Context Management** | Manual state | ‚úÖ File system | Message history |

---

## Code Comparison

### Current Implementation

```python
# graph.py (300 lines)
def planning_node(state): ...
def research_node(state): ...
def synthesize_node(state): ...
def critique_node(state): ...
def finalize_node(state): ...
def route_after_critique(state): ...

builder = StateGraph(DeepResearchGraphState)
builder.add_node("plan", planning_node)
builder.add_node("research", research_node)
# ... 50+ more lines of graph construction

# planner.py (150 lines)
PLANNER_SYSTEM_PROMPT = """..."""
planner_chain = ...
def create_research_plan(): ...

# researcher.py (200 lines)
RESEARCHER_SYSTEM_PROMPT = """..."""
researcher_chain = ...
def research_sub_question(): ...

# synthesizer.py (180 lines)
# critic.py (150 lines)
# report_generator.py (120 lines)
# schemas.py (100 lines)
# Total: 750+ lines
```

### Deep Agents (40 lines)

```python
from deepagents import create_deep_agent

research_subagent = {
    "name": "deep-researcher",
    "system_prompt": """You are an expert researcher.
    1. Use write_todos to plan sub-questions
    2. Use internet_search to research each
    3. Use write_file to save findings
    4. Self-critique and iterate
    5. Generate final report
    """,
    "tools": [internet_search],
}

agent = create_deep_agent(
    model="claude-sonnet-4-5-20250929",
    subagents=[research_subagent]
)

result = agent.invoke({"messages": [{"role": "user", "content": query}]})
```

### create_agent (100 lines)

```python
from langchain.agents import create_agent
from langchain_community.tools.tavily_search import TavilySearchResults

search_tool = TavilySearchResults(max_results=5)

RESEARCH_PROMPT = """You are an expert researcher.
Follow this process:
1. Plan: Break query into sub-questions
2. Research: Search each thoroughly
3. Synthesize: Organize into sections
4. Generate: Create markdown report
"""

agent = create_agent(
    model=ChatOllama(model="llama3.3:70b"),
    tools=[search_tool],
    system_prompt=RESEARCH_PROMPT,
    checkpointer=checkpointer
)

result = agent.invoke({"messages": [HumanMessage(content=query)]})
```

---

## Migration Steps

### Step 1: Test the Simplified Version

**For Deep Agents:**
```bash
# Install
pip install deepagents tavily-python

# Test
python deep_research_simplified.py
```

**For create_agent:**
```bash
# Already have the packages!
python deep_research_create_agent.py
```

### Step 2: Compare Outputs

Run the same research query with both:
```python
# Your current implementation
from graph import run_deep_research
result_old = run_deep_research("Research AI-powered SOCs")

# Simplified version
from deep_research_create_agent import research
result_new = research("Research AI-powered SOCs")

# Compare quality, coverage, citations
```

### Step 3: Gradual Migration

Option A - **Parallel Run** (Safest):
- Keep both implementations
- Route 10% of queries to new version
- Compare results over 1-2 weeks
- Gradually increase to 100%

Option B - **Direct Switch** (Faster):
- Replace `graph.py` imports with simplified version
- Update any external code that calls the agent
- Test thoroughly
- Deploy

### Step 4: Cleanup

Once confident in the new version:
```bash
# Archive old implementation
mkdir -p archive/old_implementation
mv agents/ archive/old_implementation/
mv graph.py archive/old_implementation/
mv schemas.py archive/old_implementation/

# Keep only simplified version
# deep_research_create_agent.py or deep_research_simplified.py
```

---

## What You Gain

### Code Simplification
- ‚úÖ **95% less code** (750 ‚Üí 40 lines)
- ‚úÖ **1 file instead of 8** files
- ‚úÖ **No custom serialization** (automatic)
- ‚úÖ **No manual routing logic** (built-in)
- ‚úÖ **Easier to maintain** and extend

### Performance Improvements
- ‚úÖ **Parallel execution** (Deep Agents)
- ‚úÖ **Better context management** (file offloading)
- ‚úÖ **Built-in optimizations** (LangChain team maintains)
- ‚úÖ **Cross-session memory** (Deep Agents)

### Developer Experience
- ‚úÖ **Standard patterns** (easier for team to understand)
- ‚úÖ **Better documentation** (LangChain docs)
- ‚úÖ **Community support** (more users)
- ‚úÖ **Regular updates** (LangChain maintains)

---

## Frequently Asked Questions

**Q: Will this be as efficient as my custom implementation?**

A: Yes, and likely more efficient because:
- LangChain's prebuilt components are heavily optimized
- Deep Agents adds parallel execution (your current is sequential)
- File system offloading prevents context overflow
- No serialization overhead

**Q: What about my custom prompts?**

A: You can keep them! Just paste your custom prompts into the `system_prompt` field. The simplified versions are just starting points.

**Q: Can I still use Ollama/llama3.3?**

A: Absolutely! Both versions support any LangChain-compatible model:
```python
# Deep Agents
agent = create_deep_agent(model="ollama:llama3.3:70b", ...)

# create_agent
agent = create_agent(model=ChatOllama(model="llama3.3:70b"), ...)
```

**Q: What if I need more control?**

A: You can still use custom LangGraph workflows! The simplified versions are great starting points, but you can always add custom nodes, edges, and logic as needed. LangGraph is fully flexible.

**Q: How do I handle the transition for existing research threads?**

A: Checkpoints from the old system won't be compatible. Options:
1. Let old threads finish with old system
2. Export state and recreate with new system
3. Start fresh (recommended)

---

## Support

- **LangChain Docs**: https://docs.langchain.com/
- **Deep Agents Docs**: https://docs.langchain.com/oss/python/deepagents/overview
- **Your Current Code**: Available in `archive/old_implementation/`

---

## Next Steps

1. ‚úÖ **Test** both simplified versions
2. ‚úÖ **Compare** output quality with your current implementation
3. ‚úÖ **Choose** Deep Agents or create_agent based on your needs
4. ‚úÖ **Migrate** using the steps above
5. ‚úÖ **Enjoy** 95% less code to maintain! üéâ
